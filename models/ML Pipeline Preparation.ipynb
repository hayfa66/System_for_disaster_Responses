{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#nltk.download(['punkt', 'wordnet','stopwords','omw-1.4'])\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3361\u001b[0m, in \u001b[0;36mEngine._wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:310\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[0;32m    305\u001b[0m \u001b[39mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m _ConnectionFairy\u001b[39m.\u001b[39;49m_checkout(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:868\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fairy:\n\u001b[1;32m--> 868\u001b[0m     fairy \u001b[39m=\u001b[39m _ConnectionRecord\u001b[39m.\u001b[39;49mcheckout(pool)\n\u001b[0;32m    870\u001b[0m     fairy\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m pool\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:476\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheckout\u001b[39m(\u001b[39mcls\u001b[39m, pool):\n\u001b[1;32m--> 476\u001b[0m     rec \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_do_get()\n\u001b[0;32m    477\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:256\u001b[0m, in \u001b[0;36mNullPool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_get\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection()\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:256\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m \u001b[39mreturn\u001b[39;00m _ConnectionRecord(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:371\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39mif\u001b[39;00m connect:\n\u001b[1;32m--> 371\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__connect()\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize_callback \u001b[39m=\u001b[39m deque()\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:665\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 665\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m    666\u001b[0m         pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mError on connect(): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_only:\n\u001b[1;32m---> 70\u001b[0m         compat\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m     71\u001b[0m             exc_value,\n\u001b[0;32m     72\u001b[0m             with_traceback\u001b[39m=\u001b[39;49mexc_tb,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:661\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi_connection \u001b[39m=\u001b[39m connection \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_invoke_creator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    662\u001b[0m pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreated new connection \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, connection)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\create.py:578\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[39mreturn\u001b[39;00m connection\n\u001b[1;32m--> 578\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\default.py:597\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams):\n\u001b[0;32m    596\u001b[0m     \u001b[39m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\Downloads\\disaster-response-pipeline-project\\disaster_response_pipeline_project\\models\\ML Pipeline Preparation.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Downloads/disaster-response-pipeline-project/disaster_response_pipeline_project/models/ML%20Pipeline%20Preparation.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load data from database\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Downloads/disaster-response-pipeline-project/disaster_response_pipeline_project/models/ML%20Pipeline%20Preparation.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m engine \u001b[39m=\u001b[39m create_engine(\u001b[39m'\u001b[39m\u001b[39msqlite:///./data/DisasterResponse.db\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Downloads/disaster-response-pipeline-project/disaster_response_pipeline_project/models/ML%20Pipeline%20Preparation.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_table(\u001b[39m'\u001b[39;49m\u001b[39mmessage\u001b[39;49m\u001b[39m'\u001b[39;49m, engine)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Downloads/disaster-response-pipeline-project/disaster_response_pipeline_project/models/ML%20Pipeline%20Preparation.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# X : the Features , Y : the catogeries\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Downloads/disaster-response-pipeline-project/disaster_response_pipeline_project/models/ML%20Pipeline%20Preparation.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m Y \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m4\u001b[39m:]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\sql.py:285\u001b[0m, in \u001b[0;36mread_sql_table\u001b[1;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39mRead SQL database table into a DataFrame.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39m>>> pd.read_sql_table('table_name', 'postgres:///db_name')  # doctest:+SKIP\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con, schema\u001b[39m=\u001b[39mschema)\n\u001b[1;32m--> 285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mhas_table(table_name):\n\u001b[0;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable \u001b[39m\u001b[39m{\u001b[39;00mtable_name\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    288\u001b[0m table \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    289\u001b[0m     table_name,\n\u001b[0;32m    290\u001b[0m     index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m    295\u001b[0m )\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\sql.py:1762\u001b[0m, in \u001b[0;36mSQLDatabase.has_table\u001b[1;34m(self, name, schema)\u001b[0m\n\u001b[0;32m   1759\u001b[0m \u001b[39mif\u001b[39;00m _gt14():\n\u001b[0;32m   1760\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m inspect\n\u001b[1;32m-> 1762\u001b[0m     insp \u001b[39m=\u001b[39m inspect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable)\n\u001b[0;32m   1763\u001b[0m     \u001b[39mreturn\u001b[39;00m insp\u001b[39m.\u001b[39mhas_table(name, schema \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mschema)\n\u001b[0;32m   1764\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\inspection.py:64\u001b[0m, in \u001b[0;36minspect\u001b[1;34m(subject, raiseerr)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m reg \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m subject\n\u001b[1;32m---> 64\u001b[0m ret \u001b[39m=\u001b[39m reg(subject)\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\reflection.py:182\u001b[0m, in \u001b[0;36mInspector._engine_insp\u001b[1;34m(bind)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39m@inspection\u001b[39m\u001b[39m.\u001b[39m_inspects(Engine)\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_engine_insp\u001b[39m(bind):\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m Inspector\u001b[39m.\u001b[39;49m_construct(Inspector\u001b[39m.\u001b[39;49m_init_engine, bind)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\reflection.py:117\u001b[0m, in \u001b[0;36mInspector._construct\u001b[1;34m(cls, init, bind)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m bind\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39minspector\n\u001b[0;32m    116\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m init(\u001b[39mself\u001b[39;49m, bind)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\reflection.py:128\u001b[0m, in \u001b[0;36mInspector._init_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init_engine\u001b[39m(\u001b[39mself\u001b[39m, engine):\n\u001b[0;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[1;32m--> 128\u001b[0m     engine\u001b[39m.\u001b[39;49mconnect()\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op_context_requires_connect \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mdialect\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3315\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self, close_with_result)\u001b[0m\n\u001b[0;32m   3300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, close_with_result\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   3301\u001b[0m     \u001b[39m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3302\u001b[0m \n\u001b[0;32m   3303\u001b[0m \u001b[39m    The :class:`_engine.Connection` object is a facade that uses a DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3312\u001b[0m \n\u001b[0;32m   3313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection_cls(\u001b[39mself\u001b[39;49m, close_with_result\u001b[39m=\u001b[39;49mclose_with_result)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:96\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, close_with_result, _branch_from, _execution_options, _dispatch, _has_events, _allow_revalidate)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39m=\u001b[39m _branch_from\u001b[39m.\u001b[39m_has_events\n\u001b[0;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbapi_connection \u001b[39m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m         connection\n\u001b[0;32m     95\u001b[0m         \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m         \u001b[39melse\u001b[39;00m engine\u001b[39m.\u001b[39;49mraw_connection()\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_transaction \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__savepoint_seq \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3394\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self, _connection)\u001b[0m\n\u001b[0;32m   3372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraw_connection\u001b[39m(\u001b[39mself\u001b[39m, _connection\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3373\u001b[0m     \u001b[39m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3374\u001b[0m \n\u001b[0;32m   3375\u001b[0m \u001b[39m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3392\u001b[0m \n\u001b[0;32m   3393\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3394\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_pool_connect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool\u001b[39m.\u001b[39;49mconnect, _connection)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3364\u001b[0m, in \u001b[0;36mEngine._wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3363\u001b[0m     \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 3364\u001b[0m         Connection\u001b[39m.\u001b[39;49m_handle_dbapi_exception_noconnection(\n\u001b[0;32m   3365\u001b[0m             e, dialect, \u001b[39mself\u001b[39;49m\n\u001b[0;32m   3366\u001b[0m         )\n\u001b[0;32m   3367\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3368\u001b[0m         util\u001b[39m.\u001b[39mraise_(\n\u001b[0;32m   3369\u001b[0m             sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[0;32m   3370\u001b[0m         )\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2198\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine)\u001b[0m\n\u001b[0;32m   2196\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[0;32m   2197\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2198\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m   2199\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[0;32m   2200\u001b[0m     )\n\u001b[0;32m   2201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2202\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3361\u001b[0m, in \u001b[0;36mEngine._wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3359\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3363\u001b[0m     \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:310\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    303\u001b[0m     \u001b[39m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[0;32m    305\u001b[0m \u001b[39m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConnectionFairy\u001b[39m.\u001b[39;49m_checkout(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:868\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    866\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_checkout\u001b[39m(\u001b[39mcls\u001b[39m, pool, threadconns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fairy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    867\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fairy:\n\u001b[1;32m--> 868\u001b[0m         fairy \u001b[39m=\u001b[39m _ConnectionRecord\u001b[39m.\u001b[39;49mcheckout(pool)\n\u001b[0;32m    870\u001b[0m         fairy\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m pool\n\u001b[0;32m    871\u001b[0m         fairy\u001b[39m.\u001b[39m_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:476\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheckout\u001b[39m(\u001b[39mcls\u001b[39m, pool):\n\u001b[1;32m--> 476\u001b[0m     rec \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_do_get()\n\u001b[0;32m    477\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         dbapi_connection \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mget_connection()\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:256\u001b[0m, in \u001b[0;36mNullPool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_get\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection()\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:256\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    254\u001b[0m     \u001b[39m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConnectionRecord(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:371\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pool \u001b[39m=\u001b[39m pool\n\u001b[0;32m    370\u001b[0m \u001b[39mif\u001b[39;00m connect:\n\u001b[1;32m--> 371\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__connect()\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize_callback \u001b[39m=\u001b[39m deque()\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:665\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfresh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 665\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m    666\u001b[0m         pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mError on connect(): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m    667\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[39m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    669\u001b[0m     \u001b[39m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_only:\n\u001b[1;32m---> 70\u001b[0m         compat\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m     71\u001b[0m             exc_value,\n\u001b[0;32m     72\u001b[0m             with_traceback\u001b[39m=\u001b[39;49mexc_tb,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m compat\u001b[39m.\u001b[39mpy3k \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info[\u001b[39m1\u001b[39m]:\n\u001b[0;32m     76\u001b[0m         \u001b[39m# emulate Py3K's behavior of telling us when an exception\u001b[39;00m\n\u001b[0;32m     77\u001b[0m         \u001b[39m# occurs in an exception handler.\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\pool\\base.py:661\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 661\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi_connection \u001b[39m=\u001b[39m connection \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_invoke_creator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    662\u001b[0m     pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreated new connection \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, connection)\n\u001b[0;32m    663\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfresh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\create.py:578\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    577\u001b[0m             \u001b[39mreturn\u001b[39;00m connection\n\u001b[1;32m--> 578\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\sqlalchemy\\engine\\default.py:597\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams):\n\u001b[0;32m    596\u001b[0m     \u001b[39m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///./data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('message', engine)\n",
    "\n",
    "# X : the Features , Y : the catogeries\n",
    "Y = df.iloc[:,4:].values\n",
    "X = df['message'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stop words\n",
    "stop = stopwords.words(\"english\")\n",
    "# append some more of the stopword\n",
    "stop.append('us')\n",
    "stop.append('pass')\n",
    "stop.append('could')\n",
    "stop.append('may')\n",
    "stop.append('maybe')\n",
    "# remove these stop word becasue it affects the model positively\n",
    "stop.remove('in')\n",
    "stop.remove('here')  \n",
    "\n",
    "def tokenize(text):\n",
    "    '''\n",
    "    \n",
    "    applying NLP process on the text\n",
    "    \n",
    "    inputs:\n",
    "    \n",
    "    text: String\n",
    "       \n",
    "    outputs:\n",
    "\n",
    "    list of cleaned text\n",
    "    \n",
    "    '''\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # nothing but the alphapets\n",
    "    text = re.sub(r\"[^a-z]+\",\" \",text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop]\n",
    "\n",
    "    clean_tokens = []\n",
    "\n",
    "    # for loop to stem the word\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).strip()\n",
    "        if tok == clean_tok :\n",
    "           clean_tok = lemmatizer.lemmatize(tok,'v').strip()\n",
    "        if tok == clean_tok :\n",
    "           clean_tok = lemmatizer.lemmatize(tok,'a').strip()\n",
    "        if tok == clean_tok :\n",
    "           clean_tok = lemmatizer.lemmatize(tok,'r').strip()\n",
    "        if tok == clean_tok :\n",
    "           clean_tok = lemmatizer.lemmatize(tok,'s').strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    # delete every word that is less than 2 alphabet except in and at    \n",
    "    clean_tokens = [w for w in clean_tokens if (len(w) > 2) | (w in ['in','at'])]\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "        [\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize,min_df= 0.002)),\n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('MltRFC', MultiOutputClassifier(RandomForestClassifier()))\n",
    "        ]\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(min_df=0.002,\n",
       "                                 tokenizer=&lt;function tokenize at 0x00000201E0441240&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;MltRFC&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(min_df=0.002,\n",
       "                                 tokenizer=&lt;function tokenize at 0x00000201E0441240&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;MltRFC&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=0.002,\n",
       "                tokenizer=&lt;function tokenize at 0x00000201E0441240&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MltRFC: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(min_df=0.002,\n",
       "                                 tokenizer=<function tokenize at 0x00000201E0441240>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('MltRFC',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dataset to Test and Train DATA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=.15 ,\n",
    "                                   random_state=8)\n",
    "# fit the pipeine\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      3014\n",
      "\n",
      "    accuracy                           1.00      3014\n",
      "   macro avg       1.00      1.00      1.00      3014\n",
      "weighted avg       1.00      1.00      1.00      3014\n",
      "\n",
      "request \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      2309\n",
      "           1       0.81      0.59      0.68       705\n",
      "\n",
      "    accuracy                           0.87      3014\n",
      "   macro avg       0.85      0.77      0.80      3014\n",
      "weighted avg       0.87      0.87      0.86      3014\n",
      "\n",
      "offer \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2993\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.99      3014\n",
      "   macro avg       0.50      0.50      0.50      3014\n",
      "weighted avg       0.99      0.99      0.99      3014\n",
      "\n",
      "aid_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69      1415\n",
      "           1       0.71      0.81      0.76      1599\n",
      "\n",
      "    accuracy                           0.73      3014\n",
      "   macro avg       0.73      0.72      0.72      3014\n",
      "weighted avg       0.73      0.73      0.73      3014\n",
      "\n",
      "medical_help \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      2711\n",
      "           1       0.56      0.20      0.30       303\n",
      "\n",
      "    accuracy                           0.90      3014\n",
      "   macro avg       0.74      0.59      0.62      3014\n",
      "weighted avg       0.88      0.90      0.88      3014\n",
      "\n",
      "medical_products \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2812\n",
      "           1       0.65      0.24      0.35       202\n",
      "\n",
      "    accuracy                           0.94      3014\n",
      "   macro avg       0.80      0.61      0.66      3014\n",
      "weighted avg       0.93      0.94      0.93      3014\n",
      "\n",
      "search_and_rescue \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2911\n",
      "           1       0.48      0.13      0.20       103\n",
      "\n",
      "    accuracy                           0.97      3014\n",
      "   macro avg       0.73      0.56      0.59      3014\n",
      "weighted avg       0.95      0.97      0.96      3014\n",
      "\n",
      "security \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      2932\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.97      3014\n",
      "   macro avg       0.49      0.50      0.49      3014\n",
      "weighted avg       0.95      0.97      0.96      3014\n",
      "\n",
      "military \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2914\n",
      "           1       0.57      0.21      0.31       100\n",
      "\n",
      "    accuracy                           0.97      3014\n",
      "   macro avg       0.77      0.60      0.65      3014\n",
      "weighted avg       0.96      0.97      0.96      3014\n",
      "\n",
      "child_alone \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3014\n",
      "\n",
      "    accuracy                           1.00      3014\n",
      "   macro avg       1.00      1.00      1.00      3014\n",
      "weighted avg       1.00      1.00      1.00      3014\n",
      "\n",
      "water \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2742\n",
      "           1       0.85      0.60      0.70       272\n",
      "\n",
      "    accuracy                           0.95      3014\n",
      "   macro avg       0.91      0.79      0.84      3014\n",
      "weighted avg       0.95      0.95      0.95      3014\n",
      "\n",
      "food \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2556\n",
      "           1       0.81      0.82      0.81       458\n",
      "\n",
      "    accuracy                           0.94      3014\n",
      "   macro avg       0.89      0.89      0.89      3014\n",
      "weighted avg       0.94      0.94      0.94      3014\n",
      "\n",
      "shelter \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      2660\n",
      "           1       0.82      0.59      0.69       354\n",
      "\n",
      "    accuracy                           0.94      3014\n",
      "   macro avg       0.88      0.79      0.83      3014\n",
      "weighted avg       0.93      0.94      0.93      3014\n",
      "\n",
      "clothing \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2958\n",
      "           1       0.59      0.36      0.44        56\n",
      "\n",
      "    accuracy                           0.98      3014\n",
      "   macro avg       0.79      0.68      0.72      3014\n",
      "weighted avg       0.98      0.98      0.98      3014\n",
      "\n",
      "money \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2919\n",
      "           1       0.67      0.02      0.04        95\n",
      "\n",
      "    accuracy                           0.97      3014\n",
      "   macro avg       0.82      0.51      0.51      3014\n",
      "weighted avg       0.96      0.97      0.95      3014\n",
      "\n",
      "missing_people \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2955\n",
      "           1       1.00      0.05      0.10        59\n",
      "\n",
      "    accuracy                           0.98      3014\n",
      "   macro avg       0.99      0.53      0.54      3014\n",
      "weighted avg       0.98      0.98      0.97      3014\n",
      "\n",
      "refugees \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2898\n",
      "           1       0.64      0.20      0.30       116\n",
      "\n",
      "    accuracy                           0.96      3014\n",
      "   macro avg       0.80      0.60      0.64      3014\n",
      "weighted avg       0.96      0.96      0.96      3014\n",
      "\n",
      "death \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2844\n",
      "           1       0.74      0.49      0.59       170\n",
      "\n",
      "    accuracy                           0.96      3014\n",
      "   macro avg       0.86      0.74      0.79      3014\n",
      "weighted avg       0.96      0.96      0.96      3014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_aid \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      2500\n",
      "           1       0.61      0.08      0.15       514\n",
      "\n",
      "    accuracy                           0.83      3014\n",
      "   macro avg       0.73      0.54      0.53      3014\n",
      "weighted avg       0.80      0.83      0.78      3014\n",
      "\n",
      "infrastructure_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2758\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      3014\n",
      "   macro avg       0.46      0.50      0.48      3014\n",
      "weighted avg       0.84      0.91      0.87      3014\n",
      "\n",
      "transport \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2836\n",
      "           1       0.67      0.17      0.27       178\n",
      "\n",
      "    accuracy                           0.95      3014\n",
      "   macro avg       0.81      0.58      0.62      3014\n",
      "weighted avg       0.93      0.95      0.93      3014\n",
      "\n",
      "buildings \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2838\n",
      "           1       0.74      0.33      0.46       176\n",
      "\n",
      "    accuracy                           0.95      3014\n",
      "   macro avg       0.85      0.66      0.72      3014\n",
      "weighted avg       0.95      0.95      0.95      3014\n",
      "\n",
      "electricity \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      2925\n",
      "           1       0.80      0.13      0.23        89\n",
      "\n",
      "    accuracy                           0.97      3014\n",
      "   macro avg       0.89      0.57      0.61      3014\n",
      "weighted avg       0.97      0.97      0.96      3014\n",
      "\n",
      "tools \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2986\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.99      3014\n",
      "   macro avg       0.50      0.50      0.50      3014\n",
      "weighted avg       0.98      0.99      0.99      3014\n",
      "\n",
      "hospitals \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2969\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.99      3014\n",
      "   macro avg       0.49      0.50      0.50      3014\n",
      "weighted avg       0.97      0.99      0.98      3014\n",
      "\n",
      "shops \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2997\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.99      3014\n",
      "   macro avg       0.50      0.50      0.50      3014\n",
      "weighted avg       0.99      0.99      0.99      3014\n",
      "\n",
      "aid_centers \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2970\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.99      3014\n",
      "   macro avg       0.49      0.50      0.50      3014\n",
      "weighted avg       0.97      0.99      0.98      3014\n",
      "\n",
      "other_infrastructure \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2841\n",
      "           1       0.00      0.00      0.00       173\n",
      "\n",
      "    accuracy                           0.94      3014\n",
      "   macro avg       0.47      0.50      0.48      3014\n",
      "weighted avg       0.89      0.94      0.91      3014\n",
      "\n",
      "weather_related \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      1929\n",
      "           1       0.85      0.81      0.83      1085\n",
      "\n",
      "    accuracy                           0.88      3014\n",
      "   macro avg       0.87      0.86      0.87      3014\n",
      "weighted avg       0.88      0.88      0.88      3014\n",
      "\n",
      "floods \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2683\n",
      "           1       0.90      0.57      0.70       331\n",
      "\n",
      "    accuracy                           0.95      3014\n",
      "   macro avg       0.92      0.78      0.83      3014\n",
      "weighted avg       0.94      0.95      0.94      3014\n",
      "\n",
      "storm \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2662\n",
      "           1       0.75      0.74      0.75       352\n",
      "\n",
      "    accuracy                           0.94      3014\n",
      "   macro avg       0.86      0.86      0.86      3014\n",
      "weighted avg       0.94      0.94      0.94      3014\n",
      "\n",
      "fire \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2974\n",
      "           1       0.50      0.10      0.17        40\n",
      "\n",
      "    accuracy                           0.99      3014\n",
      "   macro avg       0.74      0.55      0.58      3014\n",
      "weighted avg       0.98      0.99      0.98      3014\n",
      "\n",
      "earthquake \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2648\n",
      "           1       0.90      0.82      0.86       366\n",
      "\n",
      "    accuracy                           0.97      3014\n",
      "   macro avg       0.94      0.90      0.92      3014\n",
      "weighted avg       0.97      0.97      0.97      3014\n",
      "\n",
      "cold \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2939\n",
      "           1       0.62      0.27      0.37        75\n",
      "\n",
      "    accuracy                           0.98      3014\n",
      "   macro avg       0.80      0.63      0.68      3014\n",
      "weighted avg       0.97      0.98      0.97      3014\n",
      "\n",
      "other_weather \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      2824\n",
      "           1       0.55      0.12      0.20       190\n",
      "\n",
      "    accuracy                           0.94      3014\n",
      "   macro avg       0.75      0.56      0.58      3014\n",
      "weighted avg       0.92      0.94      0.92      3014\n",
      "\n",
      "direct_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      2208\n",
      "           1       0.75      0.48      0.58       806\n",
      "\n",
      "    accuracy                           0.82      3014\n",
      "   macro avg       0.79      0.71      0.73      3014\n",
      "weighted avg       0.81      0.82      0.80      3014\n",
      "\n",
      "Accuracy :-\n",
      " 94.4675 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "category_names = list(df.iloc[:,4:].columns)\n",
    "\n",
    "for i in range(len(category_names)):\n",
    "        print(category_names[i],'\\n', classification_report(y_test[:,i], \n",
    "        y_pred[:,i]))\n",
    "\n",
    "# accuracy of the model\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(\"Accuracy : -\\n\", round(accuracy.mean()*100,4) ,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "   'vect__min_df': [0,0.001,0.002,0.005],\n",
    "   'tfidf__smooth_idf': [False , True],\n",
    "   'tfidf__use_idf': [False , True]\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=2, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[CV 1/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0;, score=0.231 total time= 7.5min\n",
      "[CV 2/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0;, score=0.225 total time= 8.8min\n",
      "[CV 1/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0.001;, score=0.242 total time= 3.6min\n",
      "[CV 2/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0.001;, score=0.243 total time= 3.6min\n",
      "[CV 1/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0.002;, score=0.246 total time= 2.9min\n",
      "[CV 2/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0.002;, score=0.237 total time= 3.1min\n",
      "[CV 1/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0.005;, score=0.244 total time= 2.4min\n",
      "[CV 2/2] END tfidf__smooth_idf=False, tfidf__use_idf=False, vect__min_df=0.005;, score=0.236 total time= 2.4min\n",
      "[CV 1/2] END tfidf__smooth_idf=False, tfidf__use_idf=True, vect__min_df=0;, score=0.234 total time= 7.0min\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# accuracy of the best estimator carrying the best cobination of parameters \n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(\"Accuracy :-\\n\", round(accuracy.mean()*100,4) ,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to support the X_transform function\n",
    "url_re = '[a-zA-Z]*http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+[a-zA-Z]*'\n",
    "email_re = '[a-zA-Z_0-9-+]+@(.?[a-zA-Z_0-9-]+\\.[a-zA-Z_0-9-]+)+$'\n",
    "url = re.compile(url_re)\n",
    "eml = re.compile(email_re)\n",
    "\n",
    "def X_Transform(X):\n",
    "    '''\n",
    "    \n",
    "    transform the feature column to 4 features columns\n",
    "    \n",
    "    inputs:\n",
    "    \n",
    "    X : one column of the message\n",
    "       \n",
    "    outputs:\n",
    "\n",
    "    2d array of containing and 4 columns of :-\n",
    "\n",
    "    message : message text without numbers , emails and url\n",
    "    number : 0 or 1 if the text has a number\n",
    "    email : 0 or 1 if the text has an email\n",
    "    url : 0 or 1 if the text has an url\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Array = np.zeros((len(X),4),dtype=object)\n",
    "    \n",
    "    for i,x in enumerate(X) :\n",
    "        Array[i,0] = x\n",
    "        if url.search(x):\n",
    "            Array[i,3] = 1   \n",
    "            text = url.sub(\" \",x)\n",
    "            Array[i,0] = text    \n",
    "        if eml.search(x):\n",
    "            Array[i,2] = 1   \n",
    "            text = eml.sub(\" \",x)\n",
    "            Array[i,0] = text        \n",
    "        if re.search(r'[0-9]+',x):\n",
    "            Array[i,1] = 1   \n",
    "            text = re.sub(r'[a-zA-Z]*[0-9]+[a-zA-Z]*',\" \",x)\n",
    "            Array[i,0] = text     \n",
    "            \n",
    "    return Array      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "        [\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize,min_df=0.002)),\n",
    "        ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True))\n",
    "        ]\n",
    "        ) \n",
    "\n",
    "ct = ColumnTransformer( [('CatTr',pipeline,0)] , remainder='passthrough') \n",
    "\n",
    "Newpi = Pipeline([ ('cr', ct) ,  ('MltRFC',\n",
    "                MultiOutputClassifier(RandomForestClassifier())) ])\n",
    "\n",
    "Newpi.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Newpi.predict(X_test)\n",
    "\n",
    "# accuracy of the improved model\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(\"Accuracy :-\\n\", round(accuracy.mean()*100,4) ,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'classifier.pkl'\n",
    "pickle.dump(Newpi, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
